import time
from math import pi
import numpy as np
import swift
from spatialmath import SE3
from spatialmath.base import tr2rpy
from roboticstoolbox import jtraj
from spatialgeometry import Cuboid

# <<< use your robot >>>
from Cr3UR3editon import CR3

# ===================== Scene & task config =====================
FLOOR_TOP = 0.05
FLOOR_THICKNESS = 0.10

# Box geometry
BOX_SIZE = (0.05, 0.05, 0.06)   # (w,d,h) m

# Spawn a 3×3 grid of pick targets near the robot (tweak center & spacing if reach is tight)
GRID_ROWS, GRID_COLS = 3, 3
GRID_SPACING = 0.14               # meters between boxes
PICK_GRID_CENTER  = (0.34, -0.42) # center of 3×3 pick grid
PLACE_GRID_CENTER = (-0.34, 0.42) # center of 3×3 place grid

# Heights (world Z)
SAFE_Z  = FLOOR_TOP + 0.35
ABOVE_Z = FLOOR_TOP + 0.18
GRASP_Z = FLOOR_TOP + BOX_SIZE[2]/2 + 0.015
LIFT_Z  = FLOOR_TOP + 0.22

# Timing
DT = 0.02
T_HOME_TO_SAFE        = 1.2
T_SAFE_TO_PRE         = 0.9
T_PRE_TO_ABOVE        = 0.6
T_ABOVE_TO_TOUCH      = 0.9
T_TOUCH_TO_LIFT       = 0.9
T_LIFT_TO_SIDE_SAFE   = 1.2
T_SIDE_SAFE_TO_PRE    = 0.8
T_PRE_TO_ABOVE_2      = 0.6
T_ABOVE_TO_TOUCH_2    = 0.9
T_PLACE_TO_LIFT       = 0.9
T_LIFT_TO_HOME_SAFE   = 1.2
T_SAFE_TO_HOME        = 1.2

# Tool orientation (match your posture)
TARGET_RPY_DEG = (175.9, -12.0, -152.2)     # roll, pitch, yaw for pick
YAW_PLACE = ((TARGET_RPY_DEG[2] + 180) + 180) % 360 - 180  # flip heading for place

# Good seed that matches your elbow-forward posture
Q_SEED_DEG = [117, -42, 103, -147, -102, 0]

# Sideways pre-approach offsets so we don't sweep low over the target
PICK_PRE_OFFSET_X  = -0.12
PLACE_PRE_OFFSET_X = +0.12


# ===================== Helpers =====================
def fk_xyz_rpy(robot, q):
    T = robot.fkine(q).A
    return T[:3, 3], tr2rpy(T, unit="deg")

def line_traj(q0, q1, seconds, dt):
    n = max(2, int(seconds/dt))
    return jtraj(np.array(q0), np.array(q1), n).q

def R_from_rpy_zyx(r_deg, p_deg, y_deg):
    r = np.deg2rad(r_deg); p = np.deg2rad(p_deg); y = np.deg2rad(y_deg)
    return SE3.Rz(y) * SE3.Ry(p) * SE3.Rx(r)

def ik_relaxed(robot, T: SE3, qseed):
    # 6D → relax yaw → position-only
    sol = robot.ikine_LM(T, q0=qseed)
    if sol.success: return sol.q, True
    sol = robot.ikine_LM(T, q0=qseed, mask=[1,1,1,1,1,0])
    if sol.success: return sol.q, True
    sol = robot.ikine_LM(T, q0=qseed, mask=[1,1,1,0,0,0])
    return sol.q, sol.success

# ---- Robust pose handling (SE3 or ndarray) ----
def T_as_SE3(T_like):
    """Return an SE3 regardless of whether input is already SE3 or a 4x4 ndarray."""
    return T_like if hasattr(T_like, "A") else SE3(T_like)

def T_translation(T_like):
    """Return (x,y,z) from an SE3 or a 4x4 ndarray."""
    if hasattr(T_like, "t"):
        t = T_like.t
    else:
        M = np.asarray(T_like)
        t = M[0:3, 3]
    return float(t[0]), float(t[1]), float(t[2])

def attach_tool_fixed(T_tool_now, T_obj_now):
    """Fixed transform {}^{tool}T_obj from current world poses (SE3 or ndarray)."""
    return T_tool_now.inv() * T_as_SE3(T_obj_now)

def grid_xy(center_xy, rows, cols, spacing):
    cx, cy = center_xy
    dx = (np.arange(cols) - (cols-1)/2.0) * spacing
    dy = (np.arange(rows) - (rows-1)/2.0) * spacing
    xys = []
    for r in range(rows):
        for c in range(cols):
            xys.append((cx + dx[c], cy + dy[r]))
    return xys


# ===================== Main =====================
def main():
    # ---- Swift env ----
    env = swift.Swift()
    env.launch(realtime=True, browser=None, port=52440, ws_port=53440)

    # ---- floor ----
    floor = Cuboid(scale=[2.4, 2.4, FLOOR_THICKNESS], color=[0.92,0.92,0.92,1.0])
    floor.T = SE3(0, 0, FLOOR_TOP - FLOOR_THICKNESS/2)
    env.add(floor)

    # ---- your CR3 robot (meshes) ----
    robot = CR3()
    robot.base = SE3.Tz(FLOOR_TOP)  # sit on raised floor
    robot.add_to_env(env)

    # camera
    env.set_camera_pose(position=[1.6, 1.5, 1.0], look_at=[0.15, -0.05, FLOOR_TOP + 0.15])

    # ---- spawn 3×3 objects on pick side ----
    box_w, box_d, box_h = BOX_SIZE
    pick_xy_list  = grid_xy(PICK_GRID_CENTER,  GRID_ROWS, GRID_COLS, GRID_SPACING)
    place_xy_list = grid_xy(PLACE_GRID_CENTER, GRID_ROWS, GRID_COLS, GRID_SPACING)

    objs = []
    for (x, y) in pick_xy_list:
        obj = Cuboid(scale=[box_w, box_d, box_h], color=[0.8, 0.3, 0.3, 1.0])
        obj.T = SE3(x, y, FLOOR_TOP + box_h/2)
        env.add(obj)
        objs.append(obj)

    # ---- orientations ----
    R_pick  = R_from_rpy_zyx(*TARGET_RPY_DEG)
    R_place = R_from_rpy_zyx(TARGET_RPY_DEG[0], TARGET_RPY_DEG[1], YAW_PLACE)

    status = swift.Label("status: idle"); env.add(status)

    # ---- iterate 9 objects ----
    qseed = np.deg2rad(Q_SEED_DEG)
    q_home = robot.q  # starting joint pose

    for idx, (obj, place_xy) in enumerate(zip(objs, place_xy_list), 1):
        status.desc = f"status: plan #{idx}"
        env.step()

        # Recompute "home safe" over the current XY before each object for continuity
        T_home = robot.fkine(q_home)
        T_home_safe_pick = SE3(T_home.t[0], T_home.t[1], SAFE_Z) * R_pick
        q_home_safe_pick, _ = ik_relaxed(robot, T_home_safe_pick, qseed)

        # Read current object XY
        px, py, _ = T_translation(obj.T)
        pick_xy = (px, py)

        # ---- pick frames ----
        T_pre_above = SE3(pick_xy[0] + PICK_PRE_OFFSET_X, pick_xy[1], ABOVE_Z) * R_pick
        T_above     = SE3(pick_xy[0], pick_xy[1], ABOVE_Z) * R_pick
        T_touch     = SE3(pick_xy[0], pick_xy[1], GRASP_Z) * R_pick
        T_lift      = SE3(pick_xy[0], pick_xy[1], LIFT_Z)  * R_pick

        # ---- place frames ----
        T_side_safe   = SE3(place_xy[0] + PLACE_PRE_OFFSET_X, place_xy[1], SAFE_Z) * R_place
        T_place_pre   = SE3(place_xy[0] + PLACE_PRE_OFFSET_X, place_xy[1], ABOVE_Z) * R_place
        T_place_above = SE3(place_xy[0], place_xy[1], ABOVE_Z) * R_place
        T_place_touch = SE3(place_xy[0], place_xy[1], GRASP_Z) * R_place
        T_place_lift  = SE3(place_xy[0], place_xy[1], LIFT_Z)  * R_place

        # ---- IK chain ----
        q1, _ = ik_relaxed(robot, T_pre_above,   q_home_safe_pick)
        q2, _ = ik_relaxed(robot, T_above,       q1)
        q3, _ = ik_relaxed(robot, T_touch,       q2)   # descend to pick
        q4, _ = ik_relaxed(robot, T_lift,        q3)   # lift with object

        q5, _ = ik_relaxed(robot, T_side_safe,   q4)
        q6, _ = ik_relaxed(robot, T_place_pre,   q5)
        q7, _ = ik_relaxed(robot, T_place_above, q6)
        q8, _ = ik_relaxed(robot, T_place_touch, q7)   # descend to place
        q9, _ = ik_relaxed(robot, T_place_lift,  q8)   # release & lift

        # Back above current "home"
        q_home_safe_pick, _ = ik_relaxed(robot, T_home_safe_pick, q9)
        q_home_final = q_home  # return to same pose as we started this item

        # ---- time-parameterized segments ----
        segs = [
            line_traj(q_home,           q_home_safe_pick, T_HOME_TO_SAFE,       DT),
            line_traj(q_home_safe_pick, q1,               T_SAFE_TO_PRE,        DT),
            line_traj(q1,               q2,               T_PRE_TO_ABOVE,       DT),
            line_traj(q2,               q3,               T_ABOVE_TO_TOUCH,     DT),
            line_traj(q3,               q4,               T_TOUCH_TO_LIFT,      DT),
            line_traj(q4,               q5,               T_LIFT_TO_SIDE_SAFE,  DT),
            line_traj(q5,               q6,               T_SIDE_SAFE_TO_PRE,   DT),
            line_traj(q6,               q7,               T_PRE_TO_ABOVE_2,     DT),
            line_traj(q7,               q8,               T_ABOVE_TO_TOUCH_2,   DT),
            line_traj(q8,               q9,               T_PLACE_TO_LIFT,      DT),
            line_traj(q9,               q_home_safe_pick, T_LIFT_TO_HOME_SAFE,  DT),
            line_traj(q_home_safe_pick, q_home_final,     T_SAFE_TO_HOME,       DT),
        ]
        Q = np.vstack(segs)

        # indices for events
        lens = [s.shape[0] for s in segs]
        c = np.cumsum(lens)
        idx_grasp = c[3]-1   # end of segment 4 (descend to pick)
        idx_place = c[8]-1   # end of segment 9 (descend to place)

        # ---- animate with attach/detach ----
        grabbed = False
        T_tool_to_obj = None
        print(f"\n[#{idx}] pick @ {np.round(pick_xy,3)}, place @ {np.round(place_xy,3)}")
        try:
            for k in range(Q.shape[0]):
                robot.q = Q[k, :].tolist()

                # status
                if k < idx_grasp:
                    status.desc = f"#{idx}: approach (pick)"
                elif k == idx_grasp:
                    status.desc = f"#{idx}: grasp"
                elif k < c[7]:
                    status.desc = f"#{idx}: carry"
                elif k < idx_place:
                    status.desc = f"#{idx}: descend (place)"
                elif k == idx_place:
                    status.desc = f"#{idx}: place"
                elif k < c[-1]-1:
                    status.desc = f"#{idx}: return"
                else:
                    status.desc = f"#{idx}: done"

                # grasp event
                if (not grabbed) and (k == idx_grasp):
                    T_tool_to_obj = attach_tool_fixed(robot.fkine(robot.q), obj.T)
                    grabbed = True
                # detach at place
                if grabbed and (k == idx_place):
                    grabbed = False

                # carry follow
                if grabbed:
                    obj.T = robot.fkine(robot.q) * T_tool_to_obj

                env.step(); time.sleep(DT)
        except KeyboardInterrupt:
            pass

        # Set new home as last q for continuity into next object
        q_home = Q[-1, :].tolist()
        robot.q = q_home

    # keep sim open
    print("\nAll objects processed. Simulation stays open; press Ctrl+C to exit.")
    try:
        while True:
            env.step(); time.sleep(0.02)
    except KeyboardInterrupt:
        pass


if __name__ == "__main__":
    main()
